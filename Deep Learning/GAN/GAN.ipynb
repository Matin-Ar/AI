{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leK8lAQ2H9gZ"
      },
      "source": [
        "### 1) Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "flZ1MOT8F8kE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10, 3) # set default size of plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk-37w6cIHXx"
      },
      "source": [
        "### 2) Loading Dataset (10 points)\n",
        "\n",
        "In this notebook, you will use `MNIST` dataset to train your GAN. You can see more information about this dataset [here](http://yann.lecun.com/exdb/mnist/). This dataset is a 10 class dataset. It contains 60000 grayscale images (50000 for train and 10000 for test or validation) each with shape (3, 28, 28). Every image has a corresponding label which is a number in range 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg-CYaG9GU03",
        "outputId": "541f63c3-439f-4f4f-9eae-01e843d907d0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 337221578.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 107676172.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 94852581.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 4542/4542 [00:00<00:00, 21922357.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor(), download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wZ06E4yEHbGo"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "################ Problem 01 (5 pts) ################\n",
        "# define hyper parameters\n",
        "batch_size = 100\n",
        "d_lr = 0.001\n",
        "g_lr = 0.0001\n",
        "n_epochs = 20\n",
        "####################### End ########################\n",
        "z_dim = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CXUYiAuzGWuh"
      },
      "outputs": [],
      "source": [
        "\n",
        "################ Problem 02 (5 pts) ################\n",
        "# Define Dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "####################### End ########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWZpzWLyISi1"
      },
      "source": [
        "### 3) Defining Network (30 points)\n",
        "At this stage, you should define a network that improves your GAN training and prevents problems such as mode collapse and vanishing gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b-P5Au4tHZAT"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txyXEXCLKVKe"
      },
      "source": [
        "### 4) Train the Network\n",
        "At this step, you are going to train your network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LPNWbLh5JW1L",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "################ Problem 05 (5 pts) ################\n",
        "# Create instances of modules (discriminator and generator)\n",
        "# don't forget to put your models on device\n",
        "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
        "\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
        "D = Discriminator(mnist_dim).to(device)\n",
        "####################### End ########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Kv2HXF9gIQ-Q"
      },
      "outputs": [],
      "source": [
        "################ Problem 06 (5 pts) ################\n",
        "# Define two optimizer for discriminator and generator\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "G_optimizer = optim.Adam(G.parameters(), lr = g_lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = d_lr)\n",
        "####################### End ########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0MBLkkAnSNAH"
      },
      "outputs": [],
      "source": [
        "def D_train(x):\n",
        "    #=======================Train the discriminator=======================#\n",
        "    D.zero_grad()\n",
        "\n",
        "    # train discriminator on real\n",
        "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(batch_size, 1)\n",
        "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # train discriminator on facke\n",
        "    z = Variable(torch.randn(batch_size, z_dim).to(device))\n",
        "    x_fake, y_fake = G(z), Variable(torch.zeros(batch_size, 1).to(device))\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    return  D_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qjkIlxK5Sdwj"
      },
      "outputs": [],
      "source": [
        "def G_train(x):\n",
        "    #=======================Train the generator=======================#\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = Variable(torch.randn(batch_size, z_dim).to(device))\n",
        "    y = Variable(torch.ones(batch_size, 1).to(device))\n",
        "\n",
        "    G_output = G(z)\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    return G_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFXCjH1LLzNB",
        "outputId": "afaa7ded-c4c8-424f-89f5-8d5596a6818b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/20]: loss_d: 0.301, loss_g: 4.056\n",
            "[2/20]: loss_d: 0.300, loss_g: 4.117\n",
            "[3/20]: loss_d: 0.296, loss_g: 4.001\n",
            "[4/20]: loss_d: 0.281, loss_g: 3.962\n",
            "[5/20]: loss_d: 0.298, loss_g: 4.003\n",
            "[6/20]: loss_d: 0.301, loss_g: 3.923\n",
            "[7/20]: loss_d: 0.295, loss_g: 4.092\n",
            "[8/20]: loss_d: 0.288, loss_g: 3.994\n",
            "[9/20]: loss_d: 0.280, loss_g: 4.028\n",
            "[10/20]: loss_d: 0.287, loss_g: 4.109\n",
            "[11/20]: loss_d: 0.293, loss_g: 4.109\n",
            "[12/20]: loss_d: 0.289, loss_g: 4.045\n",
            "[13/20]: loss_d: 0.291, loss_g: 4.125\n",
            "[14/20]: loss_d: 0.295, loss_g: 3.992\n",
            "[15/20]: loss_d: 0.290, loss_g: 4.135\n",
            "[16/20]: loss_d: 0.300, loss_g: 4.080\n",
            "[17/20]: loss_d: 0.288, loss_g: 4.037\n",
            "[18/20]: loss_d: 0.296, loss_g: 3.985\n",
            "[19/20]: loss_d: 0.294, loss_g: 4.017\n",
            "[20/20]: loss_d: 0.297, loss_g: 3.997\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, n_epochs+1):\n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(x))\n",
        "        G_losses.append(G_train(x))\n",
        "\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "            (epoch), n_epochs, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtNI9PSSLxJo"
      },
      "source": [
        "### 5) Save Generator\n",
        "Save your final generator parameters. Upload it with your other files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UoyR5EIkG5Ep"
      },
      "outputs": [],
      "source": [
        "################ Problem 11 (5 pts) ################\n",
        "with torch.no_grad():\n",
        "    test_z = Variable(torch.randn(batch_size, z_dim).to(device))\n",
        "    generated = G(test_z)\n",
        "\n",
        "    save_image(generated.view(generated.size(0), 1, 28, 28), './sample_3' + '.png')\n",
        "####################### End ########################"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
