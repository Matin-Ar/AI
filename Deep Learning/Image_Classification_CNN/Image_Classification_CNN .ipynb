{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsrcohGwVhLJ"
      },
      "source": [
        "<h1 style=\"text-align: center\">\n",
        "Deep Learning </br> \n",
        "Image Classification\n",
        "</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atGYO6DvK5NU",
        "papermill": {
          "duration": 0.022376,
          "end_time": "2020-11-06T00:15:34.434234",
          "exception": false,
          "start_time": "2020-11-06T00:15:34.411858",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Import needed libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-06T00:15:34.484628Z",
          "iopub.status.busy": "2020-11-06T00:15:34.483829Z",
          "iopub.status.idle": "2020-11-06T00:15:35.592124Z",
          "shell.execute_reply": "2020-11-06T00:15:35.591266Z"
        },
        "id": "dIjCFmM1K5NX",
        "papermill": {
          "duration": 1.135699,
          "end_time": "2020-11-06T00:15:35.592273",
          "exception": false,
          "start_time": "2020-11-06T00:15:34.456574",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ih2AD9ie1MX"
      },
      "source": [
        "## Loading and Pre-Processing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaZtkgKAe2LN",
        "outputId": "4b4935a4-5c80-41a0-c487-d206814d00c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 120517250.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 95447095.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 4422102/4422102 [00:00<00:00, 62994219.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 21744488.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Download FashionMNIST dataset\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# use fashion mnist dataset\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    )\n",
        "\n",
        "test_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    )\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsktV4w-e64U"
      },
      "outputs": [],
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# split training set into train and validation data\n",
        "train_size = 48000\n",
        "val_size = 60000 - train_size\n",
        "train_ds,val_ds = random_split(train_set, [train_size, val_size])\n",
        "\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRIhgkNPe-rW"
      },
      "outputs": [],
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# Loading the dataset into memory using Dataloader\n",
        "# use your desired batch size and shuffle is necessary\n",
        "train_dataloader = DataLoader(train_ds, batch_size=20, shuffle=True)\n",
        "val_dataloader = DataLoader(val_ds, batch_size=20, shuffle=True)\n",
        "test_dataloader = DataLoader(test_set, batch_size=60000, shuffle=True)\n",
        "classes = train_set.classes\n",
        "\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVqdLxDd8O5o"
      },
      "source": [
        "**Display some images from dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "LnhmcZP9e62N",
        "outputId": "d9ef3a8c-df5f-4328-8c07-c8e38bfbe172"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_dataloader)\n",
        "images, labels = next(dataiter)\n",
        "fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(10, 8), subplot_kw={'xticks': [], 'yticks': []})\n",
        "for i,ax in zip(range(0,6),axes.flat):\n",
        "    img,label=images[i],labels[i]\n",
        "    ax.imshow(img.permute(1, 2, 0))\n",
        "    ax.set_title(f\"Label: {classes[label]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7RMnLBSK5Nc",
        "papermill": {
          "duration": 0.025997,
          "end_time": "2020-11-06T00:15:44.018664",
          "exception": false,
          "start_time": "2020-11-06T00:15:43.992667",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Defining the Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If6yxMmoqxDN"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1Euy5_bGIiiYECSZUeEofgTImJWgQ0XLf'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_UOoVg8tjwT"
      },
      "source": [
        "**<h2>Implement the model above in pytorch</h2>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d4iYGy6cwgZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#define the CNN architecture below\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding='same'))\n",
        "        self.layer2 = nn.Sequential(  \n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "        self.layer3 = nn.Sequential(  \n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding='valid'))\n",
        "        self.layer4 = nn.Sequential(  \n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "        self.fc = nn.Linear(6 * 6 * 32, 10)\n",
        "\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "450scXnLLDSl"
      },
      "outputs": [],
      "source": [
        "# Using GPU if it's available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPP8CaHv684n",
        "outputId": "c15ecc5e-077f-49bb-9743-0d13af5eed17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=1152, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn_model = Net()\n",
        "cnn_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ0Xr7KfK5Ne",
        "papermill": {
          "duration": 0.026597,
          "end_time": "2020-11-06T00:15:44.148554",
          "exception": false,
          "start_time": "2020-11-06T00:15:44.121957",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Defining Loss Function and optimizer\n",
        "**Define appropriate Loss Function, Optimizer and Learning Rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-06T00:15:44.209323Z",
          "iopub.status.busy": "2020-11-06T00:15:44.208462Z",
          "iopub.status.idle": "2020-11-06T00:15:44.211159Z",
          "shell.execute_reply": "2020-11-06T00:15:44.211695Z"
        },
        "id": "aAhczTtRK5Nf",
        "papermill": {
          "duration": 0.036545,
          "end_time": "2020-11-06T00:15:44.211856",
          "exception": false,
          "start_time": "2020-11-06T00:15:44.175311",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "Learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn_model.parameters(),lr=Learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTs7zqIuT6bI"
      },
      "source": [
        "**Define number of epochs and path to save the best model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIl4qh6gT68p"
      },
      "outputs": [],
      "source": [
        "epochs = 15\n",
        "save_path=\"/content/cnn_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE5cyPw3K5Ng",
        "papermill": {
          "duration": 0.026206,
          "end_time": "2020-11-06T00:15:44.264708",
          "exception": false,
          "start_time": "2020-11-06T00:15:44.238502",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Finally we will train our neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2czjHpINLO7A"
      },
      "outputs": [],
      "source": [
        "# multiclass accuracy\n",
        "def multi_acc(y_pred, y_test):\n",
        "    _, y_pred_tags = torch.max(y_pred, dim = 1)    \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "    acc = torch.round(acc * 100)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0JhvfcNYGwI"
      },
      "source": [
        "**Implementing the training algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXd2kTmtnv8r",
        "outputId": "be680dea-ed9a-4cc8-f717-992823f8404e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/15], Step [100/2400], Loss: 1.0234\n",
            "Epoch [1/15], Step [200/2400], Loss: 0.9047\n",
            "Epoch [1/15], Step [300/2400], Loss: 1.1038\n",
            "Epoch [1/15], Step [400/2400], Loss: 0.9138\n",
            "Epoch [1/15], Step [500/2400], Loss: 0.9613\n",
            "Epoch [1/15], Step [600/2400], Loss: 0.5839\n",
            "Epoch [1/15], Step [700/2400], Loss: 0.5147\n",
            "Epoch [1/15], Step [800/2400], Loss: 0.6262\n",
            "Epoch [1/15], Step [900/2400], Loss: 0.8419\n",
            "Epoch [1/15], Step [1000/2400], Loss: 0.5864\n",
            "Epoch [1/15], Step [1100/2400], Loss: 0.6421\n",
            "Epoch [1/15], Step [1200/2400], Loss: 0.5799\n",
            "Epoch [1/15], Step [1300/2400], Loss: 0.5402\n",
            "Epoch [1/15], Step [1400/2400], Loss: 0.4049\n",
            "Epoch [1/15], Step [1500/2400], Loss: 0.6883\n",
            "Epoch [1/15], Step [1600/2400], Loss: 0.3321\n",
            "Epoch [1/15], Step [1700/2400], Loss: 0.5752\n",
            "Epoch [1/15], Step [1800/2400], Loss: 0.6232\n",
            "Epoch [1/15], Step [1900/2400], Loss: 0.4263\n",
            "Epoch [1/15], Step [2000/2400], Loss: 0.4333\n",
            "Epoch [1/15], Step [2100/2400], Loss: 0.5083\n",
            "Epoch [1/15], Step [2200/2400], Loss: 0.3322\n",
            "Epoch [1/15], Step [2300/2400], Loss: 0.3841\n",
            "Epoch [1/15], Step [2400/2400], Loss: 0.3278\n",
            "Epoch [2/15], Step [100/2400], Loss: 0.7119\n",
            "Epoch [2/15], Step [200/2400], Loss: 0.4502\n",
            "Epoch [2/15], Step [300/2400], Loss: 0.3050\n",
            "Epoch [2/15], Step [400/2400], Loss: 0.3154\n",
            "Epoch [2/15], Step [500/2400], Loss: 0.2874\n",
            "Epoch [2/15], Step [600/2400], Loss: 0.5644\n",
            "Epoch [2/15], Step [700/2400], Loss: 0.3735\n",
            "Epoch [2/15], Step [800/2400], Loss: 0.2522\n",
            "Epoch [2/15], Step [900/2400], Loss: 0.4658\n",
            "Epoch [2/15], Step [1000/2400], Loss: 0.4901\n",
            "Epoch [2/15], Step [1100/2400], Loss: 0.3481\n",
            "Epoch [2/15], Step [1200/2400], Loss: 0.3494\n",
            "Epoch [2/15], Step [1300/2400], Loss: 0.2455\n",
            "Epoch [2/15], Step [1400/2400], Loss: 0.2968\n",
            "Epoch [2/15], Step [1500/2400], Loss: 0.5034\n",
            "Epoch [2/15], Step [1600/2400], Loss: 0.3627\n",
            "Epoch [2/15], Step [1700/2400], Loss: 0.3719\n",
            "Epoch [2/15], Step [1800/2400], Loss: 0.4198\n",
            "Epoch [2/15], Step [1900/2400], Loss: 0.4870\n",
            "Epoch [2/15], Step [2000/2400], Loss: 0.9162\n",
            "Epoch [2/15], Step [2100/2400], Loss: 0.3388\n",
            "Epoch [2/15], Step [2200/2400], Loss: 0.3714\n",
            "Epoch [2/15], Step [2300/2400], Loss: 0.2451\n",
            "Epoch [2/15], Step [2400/2400], Loss: 0.1990\n",
            "Epoch [3/15], Step [100/2400], Loss: 0.2743\n",
            "Epoch [3/15], Step [200/2400], Loss: 0.5864\n",
            "Epoch [3/15], Step [300/2400], Loss: 0.2933\n",
            "Epoch [3/15], Step [400/2400], Loss: 0.2582\n",
            "Epoch [3/15], Step [500/2400], Loss: 0.3042\n",
            "Epoch [3/15], Step [600/2400], Loss: 0.4800\n",
            "Epoch [3/15], Step [700/2400], Loss: 0.3667\n",
            "Epoch [3/15], Step [800/2400], Loss: 0.1691\n",
            "Epoch [3/15], Step [900/2400], Loss: 0.2120\n",
            "Epoch [3/15], Step [1000/2400], Loss: 0.2622\n",
            "Epoch [3/15], Step [1100/2400], Loss: 0.1991\n",
            "Epoch [3/15], Step [1200/2400], Loss: 0.1767\n",
            "Epoch [3/15], Step [1300/2400], Loss: 0.2969\n",
            "Epoch [3/15], Step [1400/2400], Loss: 0.4347\n",
            "Epoch [3/15], Step [1500/2400], Loss: 0.3944\n",
            "Epoch [3/15], Step [1600/2400], Loss: 0.3592\n",
            "Epoch [3/15], Step [1700/2400], Loss: 0.3289\n",
            "Epoch [3/15], Step [1800/2400], Loss: 0.5828\n",
            "Epoch [3/15], Step [1900/2400], Loss: 0.2726\n",
            "Epoch [3/15], Step [2000/2400], Loss: 0.4921\n",
            "Epoch [3/15], Step [2100/2400], Loss: 0.4424\n",
            "Epoch [3/15], Step [2200/2400], Loss: 0.3275\n",
            "Epoch [3/15], Step [2300/2400], Loss: 0.2937\n",
            "Epoch [3/15], Step [2400/2400], Loss: 0.8260\n",
            "Epoch [4/15], Step [100/2400], Loss: 0.3541\n",
            "Epoch [4/15], Step [200/2400], Loss: 0.2645\n",
            "Epoch [4/15], Step [300/2400], Loss: 0.5230\n",
            "Epoch [4/15], Step [400/2400], Loss: 0.3169\n",
            "Epoch [4/15], Step [500/2400], Loss: 0.2492\n",
            "Epoch [4/15], Step [600/2400], Loss: 0.3401\n",
            "Epoch [4/15], Step [700/2400], Loss: 0.6506\n",
            "Epoch [4/15], Step [800/2400], Loss: 0.4633\n",
            "Epoch [4/15], Step [900/2400], Loss: 0.3334\n",
            "Epoch [4/15], Step [1000/2400], Loss: 0.8107\n",
            "Epoch [4/15], Step [1100/2400], Loss: 0.5103\n",
            "Epoch [4/15], Step [1200/2400], Loss: 0.2559\n",
            "Epoch [4/15], Step [1300/2400], Loss: 0.4457\n",
            "Epoch [4/15], Step [1400/2400], Loss: 0.4592\n",
            "Epoch [4/15], Step [1500/2400], Loss: 0.4077\n",
            "Epoch [4/15], Step [1600/2400], Loss: 0.2616\n",
            "Epoch [4/15], Step [1700/2400], Loss: 0.4746\n",
            "Epoch [4/15], Step [1800/2400], Loss: 0.2607\n",
            "Epoch [4/15], Step [1900/2400], Loss: 0.2762\n",
            "Epoch [4/15], Step [2000/2400], Loss: 0.5217\n",
            "Epoch [4/15], Step [2100/2400], Loss: 0.4754\n",
            "Epoch [4/15], Step [2200/2400], Loss: 0.3936\n",
            "Epoch [4/15], Step [2300/2400], Loss: 0.4651\n",
            "Epoch [4/15], Step [2400/2400], Loss: 0.1255\n",
            "Epoch [5/15], Step [100/2400], Loss: 0.2664\n",
            "Epoch [5/15], Step [200/2400], Loss: 0.4061\n",
            "Epoch [5/15], Step [300/2400], Loss: 0.5273\n",
            "Epoch [5/15], Step [400/2400], Loss: 0.2151\n",
            "Epoch [5/15], Step [500/2400], Loss: 0.3922\n",
            "Epoch [5/15], Step [600/2400], Loss: 0.4483\n",
            "Epoch [5/15], Step [700/2400], Loss: 0.4927\n",
            "Epoch [5/15], Step [800/2400], Loss: 0.4575\n",
            "Epoch [5/15], Step [900/2400], Loss: 0.2315\n",
            "Epoch [5/15], Step [1000/2400], Loss: 0.6232\n",
            "Epoch [5/15], Step [1100/2400], Loss: 0.1238\n",
            "Epoch [5/15], Step [1200/2400], Loss: 0.3576\n",
            "Epoch [5/15], Step [1300/2400], Loss: 0.4412\n",
            "Epoch [5/15], Step [1400/2400], Loss: 0.3594\n",
            "Epoch [5/15], Step [1500/2400], Loss: 0.2608\n",
            "Epoch [5/15], Step [1600/2400], Loss: 0.1877\n",
            "Epoch [5/15], Step [1700/2400], Loss: 0.5456\n",
            "Epoch [5/15], Step [1800/2400], Loss: 0.1722\n",
            "Epoch [5/15], Step [1900/2400], Loss: 0.3447\n",
            "Epoch [5/15], Step [2000/2400], Loss: 0.1535\n",
            "Epoch [5/15], Step [2100/2400], Loss: 0.5291\n",
            "Epoch [5/15], Step [2200/2400], Loss: 0.3998\n",
            "Epoch [5/15], Step [2300/2400], Loss: 0.4106\n",
            "Epoch [5/15], Step [2400/2400], Loss: 0.3378\n",
            "Epoch [6/15], Step [100/2400], Loss: 0.1922\n",
            "Epoch [6/15], Step [200/2400], Loss: 0.3868\n",
            "Epoch [6/15], Step [300/2400], Loss: 0.5684\n",
            "Epoch [6/15], Step [400/2400], Loss: 0.4120\n",
            "Epoch [6/15], Step [500/2400], Loss: 0.3940\n",
            "Epoch [6/15], Step [600/2400], Loss: 0.4946\n",
            "Epoch [6/15], Step [700/2400], Loss: 0.4175\n",
            "Epoch [6/15], Step [800/2400], Loss: 0.2935\n",
            "Epoch [6/15], Step [900/2400], Loss: 0.3761\n",
            "Epoch [6/15], Step [1000/2400], Loss: 0.1723\n",
            "Epoch [6/15], Step [1100/2400], Loss: 0.1821\n",
            "Epoch [6/15], Step [1200/2400], Loss: 0.4529\n",
            "Epoch [6/15], Step [1300/2400], Loss: 0.2054\n",
            "Epoch [6/15], Step [1400/2400], Loss: 0.2722\n",
            "Epoch [6/15], Step [1500/2400], Loss: 0.4145\n",
            "Epoch [6/15], Step [1600/2400], Loss: 0.4014\n",
            "Epoch [6/15], Step [1700/2400], Loss: 0.2031\n",
            "Epoch [6/15], Step [1800/2400], Loss: 0.3877\n",
            "Epoch [6/15], Step [1900/2400], Loss: 0.3200\n",
            "Epoch [6/15], Step [2000/2400], Loss: 0.3045\n",
            "Epoch [6/15], Step [2100/2400], Loss: 0.4385\n",
            "Epoch [6/15], Step [2200/2400], Loss: 0.2151\n",
            "Epoch [6/15], Step [2300/2400], Loss: 0.1516\n",
            "Epoch [6/15], Step [2400/2400], Loss: 0.2929\n",
            "Epoch [7/15], Step [100/2400], Loss: 0.2796\n",
            "Epoch [7/15], Step [200/2400], Loss: 0.4303\n",
            "Epoch [7/15], Step [300/2400], Loss: 0.3654\n",
            "Epoch [7/15], Step [400/2400], Loss: 0.1795\n",
            "Epoch [7/15], Step [500/2400], Loss: 0.3983\n",
            "Epoch [7/15], Step [600/2400], Loss: 0.4533\n",
            "Epoch [7/15], Step [700/2400], Loss: 0.1345\n",
            "Epoch [7/15], Step [800/2400], Loss: 0.2607\n",
            "Epoch [7/15], Step [900/2400], Loss: 0.4963\n",
            "Epoch [7/15], Step [1000/2400], Loss: 0.2649\n",
            "Epoch [7/15], Step [1100/2400], Loss: 0.5956\n",
            "Epoch [7/15], Step [1200/2400], Loss: 0.3043\n",
            "Epoch [7/15], Step [1300/2400], Loss: 0.4124\n",
            "Epoch [7/15], Step [1400/2400], Loss: 0.2559\n",
            "Epoch [7/15], Step [1500/2400], Loss: 0.3441\n",
            "Epoch [7/15], Step [1600/2400], Loss: 0.2666\n",
            "Epoch [7/15], Step [1700/2400], Loss: 0.3209\n",
            "Epoch [7/15], Step [1800/2400], Loss: 0.3834\n",
            "Epoch [7/15], Step [1900/2400], Loss: 0.2471\n",
            "Epoch [7/15], Step [2000/2400], Loss: 0.3029\n",
            "Epoch [7/15], Step [2100/2400], Loss: 0.0944\n",
            "Epoch [7/15], Step [2200/2400], Loss: 0.2166\n",
            "Epoch [7/15], Step [2300/2400], Loss: 0.1975\n",
            "Epoch [7/15], Step [2400/2400], Loss: 0.1619\n",
            "Epoch [8/15], Step [100/2400], Loss: 0.1475\n",
            "Epoch [8/15], Step [200/2400], Loss: 0.1596\n",
            "Epoch [8/15], Step [300/2400], Loss: 0.3009\n",
            "Epoch [8/15], Step [400/2400], Loss: 0.0982\n",
            "Epoch [8/15], Step [500/2400], Loss: 0.1292\n",
            "Epoch [8/15], Step [600/2400], Loss: 0.5516\n",
            "Epoch [8/15], Step [700/2400], Loss: 0.3020\n",
            "Epoch [8/15], Step [800/2400], Loss: 0.2972\n",
            "Epoch [8/15], Step [900/2400], Loss: 0.4513\n",
            "Epoch [8/15], Step [1000/2400], Loss: 0.5014\n",
            "Epoch [8/15], Step [1100/2400], Loss: 0.2536\n",
            "Epoch [8/15], Step [1200/2400], Loss: 0.1031\n",
            "Epoch [8/15], Step [1300/2400], Loss: 0.0852\n",
            "Epoch [8/15], Step [1400/2400], Loss: 0.2275\n",
            "Epoch [8/15], Step [1500/2400], Loss: 0.2420\n",
            "Epoch [8/15], Step [1600/2400], Loss: 0.4145\n",
            "Epoch [8/15], Step [1700/2400], Loss: 0.4301\n",
            "Epoch [8/15], Step [1800/2400], Loss: 0.8076\n",
            "Epoch [8/15], Step [1900/2400], Loss: 0.1119\n",
            "Epoch [8/15], Step [2000/2400], Loss: 0.0754\n",
            "Epoch [8/15], Step [2100/2400], Loss: 0.2946\n",
            "Epoch [8/15], Step [2200/2400], Loss: 0.5605\n",
            "Epoch [8/15], Step [2300/2400], Loss: 0.4504\n",
            "Epoch [8/15], Step [2400/2400], Loss: 0.2846\n",
            "Epoch [9/15], Step [100/2400], Loss: 0.1154\n",
            "Epoch [9/15], Step [200/2400], Loss: 0.1202\n",
            "Epoch [9/15], Step [300/2400], Loss: 0.5575\n",
            "Epoch [9/15], Step [400/2400], Loss: 0.4449\n",
            "Epoch [9/15], Step [500/2400], Loss: 0.5171\n",
            "Epoch [9/15], Step [600/2400], Loss: 0.2598\n",
            "Epoch [9/15], Step [700/2400], Loss: 0.4193\n",
            "Epoch [9/15], Step [800/2400], Loss: 0.4366\n",
            "Epoch [9/15], Step [900/2400], Loss: 0.6725\n",
            "Epoch [9/15], Step [1000/2400], Loss: 0.3705\n",
            "Epoch [9/15], Step [1100/2400], Loss: 0.1210\n",
            "Epoch [9/15], Step [1200/2400], Loss: 0.3149\n",
            "Epoch [9/15], Step [1300/2400], Loss: 0.1650\n",
            "Epoch [9/15], Step [1400/2400], Loss: 0.4784\n",
            "Epoch [9/15], Step [1500/2400], Loss: 0.1830\n",
            "Epoch [9/15], Step [1600/2400], Loss: 0.1482\n",
            "Epoch [9/15], Step [1700/2400], Loss: 0.8781\n",
            "Epoch [9/15], Step [1800/2400], Loss: 0.5733\n",
            "Epoch [9/15], Step [1900/2400], Loss: 0.2073\n",
            "Epoch [9/15], Step [2000/2400], Loss: 0.2110\n",
            "Epoch [9/15], Step [2100/2400], Loss: 0.1790\n",
            "Epoch [9/15], Step [2200/2400], Loss: 0.2945\n",
            "Epoch [9/15], Step [2300/2400], Loss: 0.3257\n",
            "Epoch [9/15], Step [2400/2400], Loss: 0.2433\n",
            "Epoch [10/15], Step [100/2400], Loss: 0.1848\n",
            "Epoch [10/15], Step [200/2400], Loss: 0.1485\n",
            "Epoch [10/15], Step [300/2400], Loss: 0.0705\n",
            "Epoch [10/15], Step [400/2400], Loss: 0.3148\n",
            "Epoch [10/15], Step [500/2400], Loss: 0.3734\n",
            "Epoch [10/15], Step [600/2400], Loss: 0.1265\n",
            "Epoch [10/15], Step [700/2400], Loss: 0.1145\n",
            "Epoch [10/15], Step [800/2400], Loss: 0.2094\n",
            "Epoch [10/15], Step [900/2400], Loss: 0.5580\n",
            "Epoch [10/15], Step [1000/2400], Loss: 0.3002\n",
            "Epoch [10/15], Step [1100/2400], Loss: 0.1385\n",
            "Epoch [10/15], Step [1200/2400], Loss: 0.2916\n",
            "Epoch [10/15], Step [1300/2400], Loss: 0.7035\n",
            "Epoch [10/15], Step [1400/2400], Loss: 0.2215\n",
            "Epoch [10/15], Step [1500/2400], Loss: 0.1851\n",
            "Epoch [10/15], Step [1600/2400], Loss: 0.1409\n",
            "Epoch [10/15], Step [1700/2400], Loss: 0.3261\n",
            "Epoch [10/15], Step [1800/2400], Loss: 0.0596\n",
            "Epoch [10/15], Step [1900/2400], Loss: 0.4085\n",
            "Epoch [10/15], Step [2000/2400], Loss: 0.1354\n",
            "Epoch [10/15], Step [2100/2400], Loss: 0.6325\n",
            "Epoch [10/15], Step [2200/2400], Loss: 0.1744\n",
            "Epoch [10/15], Step [2300/2400], Loss: 0.3336\n",
            "Epoch [10/15], Step [2400/2400], Loss: 0.5600\n",
            "Epoch [11/15], Step [100/2400], Loss: 0.3781\n",
            "Epoch [11/15], Step [200/2400], Loss: 0.2177\n",
            "Epoch [11/15], Step [300/2400], Loss: 0.2725\n",
            "Epoch [11/15], Step [400/2400], Loss: 0.1106\n",
            "Epoch [11/15], Step [500/2400], Loss: 0.2971\n",
            "Epoch [11/15], Step [600/2400], Loss: 0.3911\n",
            "Epoch [11/15], Step [700/2400], Loss: 0.2685\n",
            "Epoch [11/15], Step [800/2400], Loss: 0.1671\n",
            "Epoch [11/15], Step [900/2400], Loss: 0.1413\n",
            "Epoch [11/15], Step [1000/2400], Loss: 0.4280\n",
            "Epoch [11/15], Step [1100/2400], Loss: 0.2238\n",
            "Epoch [11/15], Step [1200/2400], Loss: 0.1831\n",
            "Epoch [11/15], Step [1300/2400], Loss: 0.1204\n",
            "Epoch [11/15], Step [1400/2400], Loss: 0.3887\n",
            "Epoch [11/15], Step [1500/2400], Loss: 0.2411\n",
            "Epoch [11/15], Step [1600/2400], Loss: 0.2043\n",
            "Epoch [11/15], Step [1700/2400], Loss: 0.3633\n",
            "Epoch [11/15], Step [1800/2400], Loss: 0.3629\n",
            "Epoch [11/15], Step [1900/2400], Loss: 0.1352\n",
            "Epoch [11/15], Step [2000/2400], Loss: 0.3725\n",
            "Epoch [11/15], Step [2100/2400], Loss: 0.3323\n",
            "Epoch [11/15], Step [2200/2400], Loss: 0.2297\n",
            "Epoch [11/15], Step [2300/2400], Loss: 0.1893\n",
            "Epoch [11/15], Step [2400/2400], Loss: 0.6141\n",
            "Epoch [12/15], Step [100/2400], Loss: 0.2031\n",
            "Epoch [12/15], Step [200/2400], Loss: 0.2760\n",
            "Epoch [12/15], Step [300/2400], Loss: 0.3545\n",
            "Epoch [12/15], Step [400/2400], Loss: 0.2816\n",
            "Epoch [12/15], Step [500/2400], Loss: 0.2507\n",
            "Epoch [12/15], Step [600/2400], Loss: 0.3063\n",
            "Epoch [12/15], Step [700/2400], Loss: 0.2242\n",
            "Epoch [12/15], Step [800/2400], Loss: 0.1007\n",
            "Epoch [12/15], Step [900/2400], Loss: 0.2711\n",
            "Epoch [12/15], Step [1000/2400], Loss: 0.1862\n",
            "Epoch [12/15], Step [1100/2400], Loss: 0.1753\n",
            "Epoch [12/15], Step [1200/2400], Loss: 0.0795\n",
            "Epoch [12/15], Step [1300/2400], Loss: 0.1369\n",
            "Epoch [12/15], Step [1400/2400], Loss: 0.4532\n",
            "Epoch [12/15], Step [1500/2400], Loss: 0.6515\n",
            "Epoch [12/15], Step [1600/2400], Loss: 0.4000\n",
            "Epoch [12/15], Step [1700/2400], Loss: 0.2479\n",
            "Epoch [12/15], Step [1800/2400], Loss: 0.4659\n",
            "Epoch [12/15], Step [1900/2400], Loss: 0.4382\n",
            "Epoch [12/15], Step [2000/2400], Loss: 0.2462\n",
            "Epoch [12/15], Step [2100/2400], Loss: 0.1488\n",
            "Epoch [12/15], Step [2200/2400], Loss: 0.2559\n",
            "Epoch [12/15], Step [2300/2400], Loss: 0.1618\n",
            "Epoch [12/15], Step [2400/2400], Loss: 0.2565\n",
            "Epoch [13/15], Step [100/2400], Loss: 0.2917\n",
            "Epoch [13/15], Step [200/2400], Loss: 0.3145\n",
            "Epoch [13/15], Step [300/2400], Loss: 0.4120\n",
            "Epoch [13/15], Step [400/2400], Loss: 0.3628\n",
            "Epoch [13/15], Step [500/2400], Loss: 0.1606\n",
            "Epoch [13/15], Step [600/2400], Loss: 0.4891\n",
            "Epoch [13/15], Step [700/2400], Loss: 0.7509\n",
            "Epoch [13/15], Step [800/2400], Loss: 0.0721\n",
            "Epoch [13/15], Step [900/2400], Loss: 0.3341\n",
            "Epoch [13/15], Step [1000/2400], Loss: 0.1533\n",
            "Epoch [13/15], Step [1100/2400], Loss: 0.3234\n",
            "Epoch [13/15], Step [1200/2400], Loss: 0.1580\n",
            "Epoch [13/15], Step [1300/2400], Loss: 0.1527\n",
            "Epoch [13/15], Step [1400/2400], Loss: 0.1270\n",
            "Epoch [13/15], Step [1500/2400], Loss: 0.1612\n",
            "Epoch [13/15], Step [1600/2400], Loss: 0.1956\n",
            "Epoch [13/15], Step [1700/2400], Loss: 0.1191\n",
            "Epoch [13/15], Step [1800/2400], Loss: 0.1595\n",
            "Epoch [13/15], Step [1900/2400], Loss: 0.5200\n",
            "Epoch [13/15], Step [2000/2400], Loss: 0.2665\n",
            "Epoch [13/15], Step [2100/2400], Loss: 0.4003\n",
            "Epoch [13/15], Step [2200/2400], Loss: 0.7576\n",
            "Epoch [13/15], Step [2300/2400], Loss: 0.3080\n",
            "Epoch [13/15], Step [2400/2400], Loss: 0.4874\n",
            "Epoch [14/15], Step [100/2400], Loss: 0.3401\n",
            "Epoch [14/15], Step [200/2400], Loss: 0.3264\n",
            "Epoch [14/15], Step [300/2400], Loss: 0.1412\n",
            "Epoch [14/15], Step [400/2400], Loss: 0.2438\n",
            "Epoch [14/15], Step [500/2400], Loss: 0.2784\n",
            "Epoch [14/15], Step [600/2400], Loss: 0.3100\n",
            "Epoch [14/15], Step [700/2400], Loss: 0.1061\n",
            "Epoch [14/15], Step [800/2400], Loss: 0.3650\n",
            "Epoch [14/15], Step [900/2400], Loss: 0.1789\n",
            "Epoch [14/15], Step [1000/2400], Loss: 0.1691\n",
            "Epoch [14/15], Step [1100/2400], Loss: 0.4982\n",
            "Epoch [14/15], Step [1200/2400], Loss: 0.4493\n",
            "Epoch [14/15], Step [1300/2400], Loss: 0.1366\n",
            "Epoch [14/15], Step [1400/2400], Loss: 0.3986\n",
            "Epoch [14/15], Step [1500/2400], Loss: 0.2363\n",
            "Epoch [14/15], Step [1600/2400], Loss: 0.3652\n",
            "Epoch [14/15], Step [1700/2400], Loss: 0.2921\n",
            "Epoch [14/15], Step [1800/2400], Loss: 0.2512\n",
            "Epoch [14/15], Step [1900/2400], Loss: 0.1499\n",
            "Epoch [14/15], Step [2000/2400], Loss: 0.1099\n",
            "Epoch [14/15], Step [2100/2400], Loss: 0.3143\n",
            "Epoch [14/15], Step [2200/2400], Loss: 0.2004\n",
            "Epoch [14/15], Step [2300/2400], Loss: 0.5566\n",
            "Epoch [14/15], Step [2400/2400], Loss: 0.2108\n",
            "Epoch [15/15], Step [100/2400], Loss: 0.3420\n",
            "Epoch [15/15], Step [200/2400], Loss: 0.3133\n",
            "Epoch [15/15], Step [300/2400], Loss: 0.2819\n",
            "Epoch [15/15], Step [400/2400], Loss: 0.1393\n",
            "Epoch [15/15], Step [500/2400], Loss: 0.4452\n",
            "Epoch [15/15], Step [600/2400], Loss: 0.3368\n",
            "Epoch [15/15], Step [700/2400], Loss: 0.0525\n",
            "Epoch [15/15], Step [800/2400], Loss: 0.3419\n",
            "Epoch [15/15], Step [900/2400], Loss: 0.3239\n",
            "Epoch [15/15], Step [1000/2400], Loss: 0.1012\n",
            "Epoch [15/15], Step [1100/2400], Loss: 0.3712\n",
            "Epoch [15/15], Step [1200/2400], Loss: 0.1673\n",
            "Epoch [15/15], Step [1300/2400], Loss: 0.0747\n",
            "Epoch [15/15], Step [1400/2400], Loss: 0.2118\n",
            "Epoch [15/15], Step [1500/2400], Loss: 0.2459\n",
            "Epoch [15/15], Step [1600/2400], Loss: 0.3582\n",
            "Epoch [15/15], Step [1700/2400], Loss: 0.4032\n",
            "Epoch [15/15], Step [1800/2400], Loss: 0.1645\n",
            "Epoch [15/15], Step [1900/2400], Loss: 0.5128\n",
            "Epoch [15/15], Step [2000/2400], Loss: 0.4957\n",
            "Epoch [15/15], Step [2100/2400], Loss: 0.1052\n",
            "Epoch [15/15], Step [2200/2400], Loss: 0.0988\n",
            "Epoch [15/15], Step [2300/2400], Loss: 0.1514\n",
            "Epoch [15/15], Step [2400/2400], Loss: 0.0669\n"
          ]
        }
      ],
      "source": [
        "total_step = len(train_dataloader)\n",
        "for epoch in range(epochs):\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = cnn_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4B6q4vC39ry"
      },
      "source": [
        "**Accuracy Result on Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AaDdINCotbM",
        "outputId": "a8a252ec-412b-407d-8f2c-030635bb6878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images: 89.04%\n"
          ]
        }
      ],
      "source": [
        "# Testing the model\n",
        "cnn_model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = cnn_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the model on the {len(test_set)} test images: {100 * correct / total}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 247.72117,
      "end_time": "2020-11-06T00:19:37.463107",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-11-06T00:15:29.741937",
      "version": "2.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
